{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6710ea12",
   "metadata": {},
   "source": [
    "# Question Answering over Documents with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20b99dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b01fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE IF KEY IS SAVED IN FILE\n",
    "\n",
    "# Change this path to your key location\n",
    "path_to_key = \"../openai-api-key.txt\"\n",
    "\n",
    "with open(path_to_key) as fo:\n",
    "    key = fo.readline()\n",
    "    \n",
    "os.environ[\"OPENAI_API_KEY\"] = key.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b156557",
   "metadata": {},
   "source": [
    "## Q/A with a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c877bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"./state_of_the_union.txt\"\n",
    "loader = TextLoader(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba25058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e738140a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The president said that Justice Breyer is an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court, and thanked him for his service.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Justice Breyer?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d03b4a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What did the president say about Justice Breyer?',\n",
       " 'answer': ' The president thanked Justice Breyer for his service.\\n',\n",
       " 'sources': './state_of_the_union.txt'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query_with_sources(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958ccaa",
   "metadata": {},
   "source": [
    "### Q/A over PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6b79c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "path_to_pdf = \"./research_papers/attention_is_all_you_need.pdf\"\n",
    "loader = PyPDFLoader(path_to_pdf)\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226f57a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A transformer model is an architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. It is used for sequence transduction tasks such as machine translation, textual entailment, and learning task-independent sentence representations.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a transformer model?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13108130",
   "metadata": {},
   "source": [
    "## Q/A with multiple documents using VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f7d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6765640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "directory = \"./research_papers\"\n",
    "loader = DirectoryLoader(directory, glob = \"*.pdf\", loader_cls=PyPDFLoader) # can add loader_cls=TextLoader to change loader type\n",
    "documents = loader.load()\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74680384",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c8ee870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a80a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm = OpenAI(), chain_type = \"stuff\", retriever = docsearch.as_retriever())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "286decae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' GPT stands for Generative Pre-training Transformer. It is a type of language model that uses an unsupervised approach to pre-train a deep learning model on large amounts of text data. It is based on the Transformer architecture, which was introduced in the paper \"Attention Is All You Need\". GPT models are used to generate text based on a given input sentence.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is a GPT model?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7659e32",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
